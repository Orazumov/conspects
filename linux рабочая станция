Курс Linux рабочая станция.

Занятие 1.

GNU (окружение)/Linux (ядро набор загрузочных модулей,
сначала загружается bios-> загрузчик -> ядро (драйвера, клавиатура) -> графическая оболочка).

Информация по презентации.

VirtualBox (на 4 бесплатно - https://www.virtualbox.org/) / VMWare Player (на 3 бесплатно https://www.vmware.com/products/workstation-player.html)
VMWareWorkstation (на 5, но платно, можно бесплатно на 30 дней).

VirtualBox - Windows hosts - дальше нажимаем Далее и ставим.
(есть extension pack - особые требования, например имитация MV дисков - быстрее SSD, поддержка USB3)

Инструмент для интеграции - интегрировать основую систему и гостевую - копирование, перетаскивание и др. 
ставится из самого VB.

Качаем также образ Ubuntu. Есть сервер и десктоп. В десктопе все что в сервере + граф. оболочка.

LTS - долгая поддержка. На сервер обычно ставят LTS, на раб станцию лучше 19 версию.

Виртуализация - есть ресурсы, гипервизор, который их распределяет и виртуальные ОС.

Мы работаем с KWM - гарантированное исп. ресурсов. Будут исп. все ресурсы компьютера.
(openvz  - не гарантирует ресурсы).

VM VirtualBox

Создать: 
имя - UbuntuGroup2
Ubuntu (64bit). Если доступно только 32 бит, значит отключена виртуализация, включить ее в биосе.


512 МБ+ для консоли, десктоп 4ГБ+ Лучше 8.

Создать, объем - не меньше 20Гб.
VDI диск.
QEMU - машина с открытым исх. кодом, но вирт. хуже.

Фикс вирт жест. диск. (некоторые ubuntu не понимают динамич).

Шифрование не нужно.

Система: 

EFI нужно ставить, если хотим работать с разметкой диска GU id, но тратится больше места.
обычно не делают.

Процессор - 2 ядра.
Включить PAE/NX если 32разрядная система.
Nested - это если внутрь виртуалки еще одну виртуалку.

Дмсплей - макс. количество памяти 128 МБ (если новая плата).

Контроллер: VboxVGA/VBoxSVGA - так удобнее с прокруткой.

Аудио - снять галочку есл ине нужен звук с вирт машины.

Сеть - NAT: 

Есть NAT и Bridge:

NAT

VM
|
PC   ---  Router
PC контролирует VM.

Bridge

VM
|
PC  ---   Router
VM тоже общ с роутером, VM получает адрес с Routera. все что на виртуалке тоже может быть видено из интернета.

NAT безопаснее, но чтобы общ. с VM нужно открывать порты для SSH.
(сеть - проброс портов - потом).

Запуск - выбираем образ Ubuntu.

lsblk - посмотреть диски.
sda - scazy drive.

меняем разметку:
sudo cfdisk /dev/sda
выбираем dos (т.к. VDI выбрали до этого)
Далее разбиваем диски.

Раслкадку лучше английский.

Минимальная установка.

Стороннее ПО не надо, драйвер лучше отдельно ставить для NVidia.

Стереть диск и установить убунту.

Ошибка:

у меня при запуске виртуалки выдает ошибку
Call to VidMessageSlotMap failed: Last=0xc000000d/87 (VERR_NEM_VM_CREATE_FAILED).


Код ошибки: 
E_FAIL (0x80004005)
Компонент: 
ConsoleWrap
Интерфейс: 
IConsole {872da645-4a9b-1727-bee2-5585105b9eed}

Решение:

в настройках виртуальной машины зайди система -> процессор -> и убери галочки с (включить Nested VT- x / AMD-V
это первый способ, второй как я понял через биос делаеться

Система поставилась, перезагрузить.

Устройства - подключить (последняя строка в меню).

Перезагружаемся, чтобы заработал drag, drop, копирование.

Нет SSH server.

в команлной строке:

ls

sudo ss -tulpan
вводим пароль.

все порты, ищем 22 порт, слежбы SSH = ничего этого нет.

sudo apt install ssh-server
apt - пакетный менеджер.
копируем openssh-server 
sudo apt install openssh-server 
y + enter

sudo ss -tulpan

порт появился.

Надо прокинуть порт -> VirtualBox Сеть прокинуть порт
SSH TCP 127.0.0.1  2222  адрес гостя?

В консоли: 

ip a scazy
см. enp0s3  - копируем оттуда IP и порт.

добавляем в virtualbox.

перегружаем вирт машину.

отключение брендмауэра:
sudo ufw status

sudo ufw disable

-----------------

ssh -p 2222 group@127.0.0.1

если не пробрасывается, переключаем на Bridge (вместо NAT).

поменялся IP  в вирт машине, теперь подключ на него.

ssh group@127.0.0.1

подключились:

ls

ls /

на win ставим putty.


Лекция 2.


lsb_release -a  - сведения о системе.

важно - Codename, может быть нужен для того чтобы установить нужное приложение.

если не знаем команду полностью, жмем tab, дополняет команду.

man lsb_release - информация о команде.

выход из информации - q

lsb_release -h - коротко показать ключи команды.

ls --help тоже самое.

pwd - текущая директория.

sudo su - стать root.

cd ~ - перейти в домашний каталог root.

ls -l - сокращенный вывод инф., тут показаны все флаги.

nano .bash_history - посмотреть историю с предыдущего сеанса.
для выхода cntrl + X

Настройка общей папки.

1. Создаем на основной машине папку.
2. VBox: настройки, общие папки, добавить. Авто подключение.
точка: /media/public
Создать постоянную папку.
ОК.
3. На виртуальной машине в проводнике есть папка наша.

Если у нас нет прав на папку:

cat etc/group - смотрим все группы.

groups - в каких группах наш пользователь.

добавляем в группу пользователя:
sudo usermod -aG vboxsf group (пользователь) - группы смотрим в док. VB.
перегружаем систему.

mkdir - создаем директорию.

nano my.txt - создаем файл.

Если слетел контроллек при перезапуске (бывает если виртуалку выкл резко, экран не растягивается):
1. Выкл машину.
2. Настройки в VB - дисплей: VboxVGA - меняем на др. ОК, потом снова как было ОК.

Создаем файл:

1. Через редактор:

nano file1.txt (расширение в терминале не играет роли, поэтому txt не обязательно, играет роль, если смотрим с граф. редактора GNOME).
cntrl + o, cntrl + x

2. touch file5.txt   (изначально это команда изм. времени мод файла)
создали пустой файл.
далее: nano file5.txt

Удалить файл:

rm file5.txt

Быстро стереть введенную строку: cntrl + W

Интерактивный поиск: 

cnrl + r

как узнать размер файла:

nano .bashrc

в файле есть инф. о размере.

HISTSIZE
 - размер истории комманд в баш.

cd .. - выйти наверх.

Если в каталоге есть файлы, мы не можем его удалить через rm

rm -r ./test2/* - удаляем все что есть в директории.
или rm -rf ./test2/* - rf - не предупреждать если нет прав на удаление.

rm -r test2/ удалем каталог.

откуда команда:

whereis ls - откуда взята команда.
echo $PATH - все пути, которые есть.
есть путь usr/bin, по которому прописана команда.
значит она работает, все ок.

программу нужно ставить в /usr/local/sbin: т.о. все пользователи будут ей пользоваться.

если для опред. пользов: 

под пользователем:
nano .profile - смотрим какие в нем дир. $HOME/bin - сюдя и записываем скрипт для пользователя.

cp ls ls2 - копируем.

type ls 

man -k passwd - смотрим весь мануал где есть passwd и потом уже man конкретной доки.

ls -l |grep file

cat /etc/services | wc -l

cat /etc/services | grep udp | wc -l

Потоки... досмотреть.



ls -l > file.txt - перенаправление в файл вывода команды.
ls -l >> file.txt - дописать в файл дальше.

ls -l a1 > file.txt
не работает, т.к. по умолчанию перенаправляется stdout:

ls -l a1 2 > file.txt - записался текст ошибки.

если нужно перенаправить оба потока:

ls -l . a1 1>file.stdout 2>file.stdout

в файле только ls - нет ошибки, т.к. одна команда затерла другую - сначала записалась ошибка, потом вывод.

ls -l . a1 1>>file.stdout 2>file.stdout

так записалось все.

ls -l . a1 1>>file.stdout 2>file.stdout

в разные файлы:

ls -l . a1 1>file.stdout 2>file.stderr

сокращенно:

ls -l . a1 &>file.txt
cat file.txt - тут все.

& - оба потока.

ls -l . a1 > file.txt 2>&1
тоже самое что и выше.

перенаправить в черную дыру:
(все данные не залогируются, улетят в никуда)

ls -l . a1 2> /dev/null - в никуда.

ошибки улетели в черную дыру.

Задачка:

ls -l > ourfile.txt
cat ourfile.txt

размер файла 0 - почему?

выполнение справа налево:

создался пустой файл и записался так в лог, как пустой.

grep std < ourfile.txt

считываем, отдаем грепу и он ищет в файле (справа на лево).

touch t1
mkdir t1 

невозможно создать каталог - имя уже есть. но тут все есть файл, поэтому не могут быть одинковые имена.

sudo apt-get install virtualbox-guest-additions-iso

поставить через терминал)

КАК ПОСМОТРЕТЬ КОЛИЧЕСТВО ФАЙЛОВ В ПАПКЕ LINUX
Самый простой способ решить эту задачу - использовать утилиту ls вместе с утилитой wc. Они покажут сколько файлов находится в текущей папке:

ls -l | wc

общая папка: 

C:\Common_folder

/media/public

вывод скрытых файлов и подсчет их:

ls -lad ./.* (последнее - маска)

ls -lad ./.* | grep ^-  (^ - начало строки, $ - окончание строки).

ls -lad ./.* | grep ^- | wc -l

find . (где ищем - текущий) -maxdepth 1 (глубина на которую ищем) -type f (тип - файл)

find . -maxdepth 1 -type f | grep "\./\." - точка экранируется слешом (нам не нужно чтобы выдавалось все - как 
будет просто по точке, а нужно чтобы выдавались файлы именно с точной в имени).

ps - текущие процессы
ps -aux - все процессы.

kill - завершаем процесс, лучше от sudo.

Вывод устройств:

lsof -a -u group (пользователь - group)

lsof -a -u group +d /dev/

нужно получить 9й столбец:

lsof -a -u group +d /dev/ | awk '{print $9}' | sort | uniq
awk - выхватывает данные, которые нужно передать в скрипт.

Cоздайте директорию для хранения фотографий, в ней должны быть директории по годам, (например, за последние 5 лет), и в каждой директории года по директории для месяца.

echo {2000..2005}

распечатывавется до полного вида: 2000, 2001, 2002,...

работает с латицией, цифрами, но с кирилицей не работает!

цикл:

for y in {2015..2020}; do for m in {01..12}; do mkdir -p (вложенная директория) .$y/$m; done; done;

Использовать команду cut на вывод длинного списка каталога, чтобы отобразить только права доступа к файлам. 
Затем отправить в конвейере этот вывод на sort и uniq, чтобы отфильтровать все повторяющиеся строки. 
Потом с помощью wc посчитать различные типы разрешений в этом каталоге. Самостоятельно решить задачу, 
как сделать так, чтобы в подсчет не добавлялись строка Итого и файлы . и .. (ссылки на текущую и родительскую 
директории)

ls -l | cut -c2-10 (отсекли в выводе первые 10 символов)

ls -l | grep -v .того | cut -c2-10 | sort (grep -v - исключить!)

ls -l | grep -v .того | cut -c2-10 | sort | uniq | wc -l

чтобы создать нового пользователя и дать ему права рута:

less /etc/passwd - тут хран все права пользователя.

root:x:0:0:root:/root:/bin/bash
(ДОПИСАТЬ ЧТО ЧТО ЗНАЧИТ)
x - хэш пароля хранится отдельно.
0 - id всегда рута.
до 1000 - служебные, от 1000 обычные.

где хранятся группы:

nano /etc/group

root:x:0 - группа рута.

sudo nano /etc/shadow

root! - от пользователя нельзя войти по ssh.
нужно менять пароль или ставить через pswd
т.е. если от рута видно хэш, нужно его сбросить!

group:R$R$#F#$F$@@#$65353543%#$ - хэш.
преобразовать в пароль обратно нельзя, но можно сравнивать - у одних паролей одни и те же хэши.

md5sum file1.txt - вывести хэш файла.

ls -l

drwxr-xr-x 14 group group
			  пользователь группа.
rwx - права пользователя
r-x - права группы  
r-x - права всех остальных

система смотрит не по группе, а по числу группы, см. в файле: nano /etc/group

можно отредактировать группу и поставить свой номер, но он должен быть уникальным.

если создаем пользователя в ручную, то id пользователя и группы д.б. > 1000.

r - чтение
w - запись
x - выполнение

ls -ln - вывести числа вместо быкв группы и польз.

в линуксе владелец файла всегда один, одна группа. все остальные пользов - под правами как остальные.

создаем файл:

touch file1.txt

ls -l

пусть хотим чтобы все могли записывать:

chmod o+w (other/g - group/u - user + write) file1.txt

chmod u-w file1.txt - убрали права.

chmod a -rwx file1.txt - забрать права у всех.

rm file1.txt - система спросит нужно ли точно удалить.

если rm -f file1.txt - удалить без вопросов.
осторожнее с этим.

задание прав с помощью цифр:

r = 4
w = 2
x = 1

rwx = 7
000 - нет прав вообще.
661 - пользователь и группа читают записывают, все остальные - выполняют.

chmod 661 file1.txt

Inode:

df -h - инф о дисках.

sudo -l /dev/sda1

лучше смотреть: 

df -i - тут смотрим сколько inode свободно.

ищем: Inode count: сколько их, столько файлов и каталогов.

Inode задаются в процессе форматирования, их можно увеличить только физически примонтировать диск и создать на нем 
папку или файл.

inode - ячейка, в ней владелец файла, права и группа. но не путь к файлу.

есть системы zfs, xfs - там inode динамически, в ext4 они неизменны.

Смотрим inode у файла:

ls -li

где хранится имя файла:

в каталоге:

pwd

/home/group - тут хранится имя, к которому привязвается inode, а в ней уже права.

sudo adduser user1 - создаем нового пользователя.

Для конфига: 

Для того, чтобы иметь доступ к файлу из другой папки.
И у нас не было дублирования - если копируем файл.

hardlink:

ln file1.txt file_ln.txt
ls -l 
у них один inode, в них одинаковое содержимое.
два имени указывают на 1 inode.

Смотрим это:

ls -li - одна inode у ссылки и у файла.
+ - не занимается inode.
- - всегда одни и те же права.

smartlink(softlink):

ln -s file_ln_soft.txt file1.txt
   на какой файл ссылка наш файл		
(права у него - только права на ярлык, не на файл. даже если все доступно, ничего страшного).

=============================

Про root и его права:

ksik,
При установке системы вы создаёте не root-суперпользователя, а "админа", которой может через sudo и ввод своего пароля, временно получить права Суперпользователя. Все следующие пользователи по-умолчанию - "обычные", не "админы" и sudo им вообще не полагается. Можно включить "обычного пользователя" в группы "adm" и "admin" (а лучше ввести рекомендованную вам команду с цифрами), и тогда и второй пользователь, уже под своим собственным паролем, получит доступ к sudo.

И при любом раскладе:
1) Root (Суперользователь) заблокирован и, по сути, не имеет пароля.
2) Дать кому-то права  "Админа" и не дать доступ к sudo, может быть и можно (точно не знаю), но абсолютно бессмысленно. Ибо суть "админской учётки" в доступе к sudo. 

==============================

Как дать юзеру доступ к sudo:

создаем юзера
Код: [Выделить]
adduser имя_пользователя
добавляем его в те же группы, что и пользователя, созданного при установке, т.е. имеющего все права
Код: [Выделить]
usermod -aG 4,24,27,30,46,109,124 имя_пользователя

4 - adm
24 - cdrom
27 - sudo
30 - dip
46 - plugdev
119 - lpadmin
130 - lxd
131 sambashare
998 - vboxsf (общая папка обмена файлами).


В принципе, достаточно группы admin.

su - переключиться на другого пользователя.

Регулярные выражения.

ДЗ.

задание 4.

1. можно так:
sudo useradd -ou 0 -g 0 username  (id пользователя и группы).
но это пользователь как root, он может делать все что угодно в системе.

есть скрипты безопасности, которые не пропустят такого пользователя.

2. можно так:

sudo useradd -m (дом. директория) -s /bin/bash (оболочка) username

sudo nano etc/passwd - смотрим нового пользователя.
id username

sudo passwd username - меняем пароль у пользователя.

sudo su username - переключились на пользователя.

exit - переключиться обратно на себя.

можно войти рутом:

sudo su

sudo -i 

это возможно, т.к. система спрашивает пароль не рута, а того, кто 
задает эту команду. Для этого нужно чтобы пользователь был в группе sudo (администратором).

sudo less etc/sudoers

сотрим файл, который описывает правила для пользователей: 

sudo less etc/sudoers | wc -l
30

sudo grep -v ^# etc/sudoers (убрать все что начинается с #, т.е. все комментарии).

sudo grep -v ^# etc/sudoers | grep -v ^$ (строка  началасть, закончиласть) - исклюсили пустые строки.

%sudo ALL =(ALL:ALL)                          ALL
	 хост	 от какой группы выполн процесс   какие команды можно выполнять.
хост = domain если нет LDAP сервера.
	 
правим файл:

sudo EDITOR = nano (проще в nano, чем в vim) visudo  

дописываем:

group 			ALL=(ALL:ALL) NOPASSWD: /bin/echo test
(пользователь)

можно дать ему вводить команды без пароля, тут также удобно давать привиллегии и забирать их.

проверяем: sudo echo test - без пароля.
sudo echo test2 - пароль.

! лучше всегда использовать sudo, а не su, т.к. su бывает не установлен.

можно также переключиться через sudo -s
(сохраняется путь, на котором были до переключения).

Задание 6:

* Создать в директории для совместной работы поддиректорию для обмена файлами, но чтобы 
удалять файлы могли только их создатели.

Решается через sticky bit:

ls -ld /tmp/

drwxrwxrwt - все могут писать, а удалять - только  создатели.

ставим стики бит:

chmod o+w /tmp/
chmod u+w /tmp/

chmod +t tmp/

SUID:

ls -l /usr/bin/passwd

-rwsr-xr-x

S - можем запускать процесс от обычного пользователя, а он будет запускаться как от рута.
т.е. эту программу может запустить любой, у кого есть права для запуска, т.е. все(r-x в конце).

passwd - меняем свой пароль без sudo, т.к. тут стоит этот бит.

chmod +s script.sh ставим suid bit.

Создать директорию, в которой есть несколько файлов. Сделать так, чтобы открыть файлы можно 
только, зная имя файла, а через ls список файлов посмотреть нельзя.

mkdir h7

cd h7

touch file1
nano file2

cd ..

chmod a-r h7/

у всех нет прав на чтение.

ls ./h7/ 
отказано в доступе.

но можем перейти в каталог и открыть конкретный файл, если знаем какой там файл.

чтобы нельзя было сделать cd:

chmod a+r h7/
chmod a-x h7/

ls h7 -l

-?????? ? ? ? ?

из-за того что нет x.

Регулярные выражения.

Изначально включался в язык Perl, сейчас используется как в Питоне, так и в Java и т.д.

Если хотим выхватить инф.:

ip a

Для грепа флаг -P позволяет исп. рег. выражения все.

ip a | grep -P "[]"
[] - один символ.
[0-9a-f] - диопазон.
[01234567abcdf] - набор - просто перечисляют.

итак:
мы убираем лишнюю инф.

ip a | grep -P "[0-9a-f][0-9a-f]:" - не оптимально, 2 раза писать.

ip a | grep -P "[0-9a-f]{2}:" - {2} - 2 повторения
{1,3} - можно и так. повтор 1 или 3 раза.

далее:
подгоняем чтобы было похоже на тот ip адрес, который нам нужно вывести и отсечь все остальное.

ip a | grep -P "[0-9a-f]{2}:[0-9a-f]{2}:[0-9a-f]{2}:[0-9a-f]{2}:[0-9a-f]{2}:[0-9a-f]{2}"

уже рабочий вариант, но можно доработать:

ip a | grep -P "([0-9a-f]{2}:){5}[0-9a-f]{2}" - 5 раз, чтобы в конце выражения не повторялось не нужно двоеточие.

делаем двоеточие опциональным в конце, чтобы сделать еще короче.

ip a | grep -P "([0-9a-f]{2}:?){6}" ? - опционально.
:+ - обязательно 1 и более раз.
:* - ноль и более.

Тестирование рег. выражений:

Командой echo:

echo 200 | grep -P "[0-10]" - распространяется только на 1 символ.

echo 200 | grep -P "[0-255]" => анализатор сокращает так:
echo 200 | grep -P "[0125]" (лишнюю пятерку сокращает, расписывает 012 вместо -).

echo @208@ | grep -P "@(25[0-5])|(2[0-4][0-9])|(1[0-9][0-9])|[0-9]{1,2}@"

						сначала рассматриваем 250 - 255, потом 200 - 249, потом 100 -199, потом 0 - 99
Задача, т.к. в IP адресе могут быть числа от 0 до 255.


если целиком весь адрес выдаляем:
echo @192.168.0.208@ | grep -P "@(((25[0-5]) | (2[0-4][0-9]) | (1[0-9][0-9]) | [0-9] {1,2})\.?){4}@"

Выделение белых IP адресов:
echo 172.32.33.33 | grep -P "\b(?!(10)|192.168|172.(2[0-9]|1[6-9]|3[0-1]))[0-9]{1,3}.(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?).(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?).(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)"

мы задаем правила исключения, они проверяются отдельно от правил валидности IP. Можно сказать, что проверка проходит в 2 этапа: мы отсеиваем серые IP и проверяем все 4 октета с самого начала, как будто исключений IP не было.

[0-9]{1,3} - это описание для 1 октета (байта) IP. Вместо [0-9]{1,3} в идеале должна быть проверка на допустимый диапазон, которую мы рассматривали на занятии. Конструкция повторяется 3 раза, так как [0-9]{1,3} описывает первый октет IP, 3 другие октета описывает конструкция, которая повторяется 3 раза. Здесь самая важная часть идет в самом начале выражения, так как она позволяет нам исключить ряд диапазонов серых IP (недоступных в сети интернет).

Bash программирование.

ДЗ.

2. echo .gif | grep -P "\.(gif|jpeg|png)$"
						gif или png или jpeg вконце $ чтобы не прошли файлы
						gif.sh - какие-то левые скрипты.
						
Чтобы показать URL: | grep -P "^https?://.+\.(gif|jpeg|png)$"		

3. Показать только белые ipшники:

Сервые IP:

192.168.х.х
10.х.х.х
172.16.х.х - 172.31.х.х

Будем использовать негативный поиск:

Пример: echo "onetwotwoone" | grep -P "one(?!(one))"
look ahead negative: найден one, т.к. на ним не следует другой one.

Пример: echo "onetwotwoone" | grep -P "one(?!(two))"
найден только последний one, т.к. за ним не следует two.
 
echo 175.35.35.33 | grep -P "\b(?!(10)|192\.168)([0-9]{1,3}\.)([0-9]{1,3}\.)([0-9]{1,3})"

"\b - это граница слова, с чего слово начинается.

вместо [0-9] можно написать: [\d]

заканчиваем:

echo 175.35.35.33 | grep -P "\b(?!(10)|192\.168|172\.(2[0-9]|1[6-9]|3[0-1]))([0-9]{1,3}\.)([0-9]{1,3}\.)([0-9]{1,3})"

4. Задание.

echo "onetwotwoone" | grep -P "(?<!(two))one"

нашел только первый one, т.к. перед ним не идет two.

echo file.exe | grep -P ".*\..{2,3}"
проходит все.

теперь добавляем негативный поиск:
echo file.exe | grep -P '.*\..{2,3}(?<!\.exe|\.sh)$'

============================================================

bash:

touch hello.sh

открываем файл в nano, программируем:

#!/bin/bash
# - где находится оболочка bash - далее путь.

#Comment 1. - далее с # - это просто комментарии.

echo "Hello world, BASH!";   (; не обязательно)

выполняем файл:

./hello.sh

нет прав, добавляем:

chmod +x hello.sh

./hello.sh

отработало!

далее в файле:

создаем константы и переменные. константа - это переменная, которая не меняется.

2 стандарта:

1. переменные - upper case.
2. большими константы, маленькими - переменные.

NAME="Igor"
# тут пробелов не должно быть.

echo "Name os ${NAME}"

Константа:

declare -r GROUP_ID="Linux-1"
(-r - read only)
можно также CamelCase.

echo "The name of group is ${GROUP_ID}"

#Group_ID нельзя менять далее.

Условия:

if открытие условия
fi закрытие условия

if [ "$NAME" == "Ivan" ]
then
		echo "The name is Ivan!"
fi
# тут не важно сколько пробелов.

read -p "Please, enter your name: " NAME

# ввод имени в переменную NAME.

if [ "$NAME" == "Ivan" ]
then
		echo "The name is Ivan!"
elif [ "$NAME" == "Anna" ]

# регистр в имени "Anna" имеет значение. если введем anna - это будет разное имя.

		echo "The name is Anna!"
else

		echo "The name is NOT Anna and Ivan!"

fi

# проверка существования файла:

FILE="./test.txt"

if [ -e "#FILE" ]     # -e - ключ "exists", проверка.
then 
		echo "$FILE exists"
		
else

		echo "$FILE is not exists!"
		
fi

# проверка доступен ли файл для записи и исполнения и чтения:

FILE="./test.txt"

if [ -e "#FILE" ]     # -w - ключ "writable", проверка.
then 
		echo "$FILE writable"
		
else

		echo "$FILE is not writable!"
		
fi


FILE="./test.txt"

if [ -e "#FILE" ]     # -x - ключ "executable", проверка.
then 
		echo "$FILE executable"
		
else

		echo "$FILE is not executable!"
		
fi


FILE="./test.txt"

if [ -e "#FILE" ]     # -r - ключ "readable", проверка.
then 
		echo "$FILE readable"
		
else

		echo "$FILE is not readable!"
		
fi

# когда запускаем, проверка идет для того имени от которого запускаем.

Цикл:

COLORS="red white black orange"

for COLOR in $COLORS   ($, т.к. перем уже сущ.)
		do 
			echo "Color is $COLOR"
		done

написали инф. в text.txt

считываем построчно, не знаем сколько строк будет:

LINE=1

while read -r THIS_LINE   # цикл сам остановится когда закончится файл и в THIS_LINE будет null, условие false.
						  # read читает строку целиком.
do 
	echo "$LINE: $THIS_LINE"
	((LINE++))

done < "$FILE" # считать весь файл и отдать его в цикл.

Функции.

Необходимы для переиспользования кода.

function test()
{
	echo "It is test function!"

}

test   # вызов функции, без скобок.

test "Ivan" "30"
test "Igor" "27"
test "Anna" "25"

function test()

{

	echo "It is test function! Name is $1, age is $2"    $1 - агрументы по порядку.

}

# $0 - путь к скрипту. $* - все параметры.

создаем файл для скрипта:

touch params
chmod +x params

открываем файл:

#!/bin/bash

echo $0;
echo $1;
echo $2;

когда запускаем файл со скриптом - выдаются на экран эти параметры, т.к. echo.

./params Anna 25

echo {2015..2020} - перебор годов на экране.

#выполнение команды напрямую:
ls -l

#выполнять и результат класть в переменную:

DATE=`date`  #вернет дату

echo "Data is $DATE"

Скрипт по backup:

echo $PATH - вывод папок, куда можно класть скрипты и откуда они будуть 
автоматически браться.

mkdir backups
mkdir data
mkdir data2

cd data

touch file1.txt   # сюда записали данные.
touch file2.txt
touch file3.txt

cd data2

touch file1.txt
touch file2.txt

mkdir tmp  # внутри data2

cd tmp

touch tmp1.txt
touch tmp2.txt

cd bin/bash

touch backup.sh

chmod +x backup.sh

открываем файл:

TAR_NAME="$(date +%Y-%m-%d-%H-%M-%S)"    # продумываем имена для архивов бэкапа. год, месяц, день и т.д.

tar -czvf "/home/group/lesson5/backups/tar-$TAR_NAME.tgz" \
--exclude=/home/group/lesson5/data2/tmp \  # что исключаем из архива.
/home/group/lesson5/data \
/home/group/lesson5/data2

# \ - продолжение кода на следующей строке.
# -czvf флаги команды - создать арх, заархив gzip, посмотреть, создать файл.

выходим из файла:

backup.sh - запускаем, т.к. скрипт лежит в папке bin, можно запускать без пути.

# желательно настроить отчистку старых архивов, чтобы они не переполняли диск:

TAR_NAME="$(date +%Y-%m-%d-%H-%M-%S)"   

find /home/group/lesson5/backups -mtime +30 -type f -delete # автоматически находим файлы старше 30 дней и удаляем их.

tar -czvf "/home/group/lesson5/backups/tar-$TAR_NAME.tgz" \
--exclude=/home/group/lesson5/data2/tmp \  
/home/group/lesson5/data \
/home/group/lesson5/data2

# добавляем в crone - чтобы в ручную не запускать скрипт:

crontab -l

crontab -e

nano 
	
в файле описываем задание:

1,3,5 10   # запускать в 10 часов 1 минуту, 3 минуты и 5 минут.

* * * * *  (минуты(0-59), часы (0-23), дни месяца (1-31), месяц (1-12), день недели (0-6, 0 - воскресенье, 6 - суббота))

путь ко скрипту:

* * * * * home/bin/backup.sh
 
* - каждую минуту, час и т.д.

cd lesson5
mkdir logs

обратно в crontab:

* * * * * home/bin/backup.sh >> /home/group/lesson5/logs/backups.log 2>&1   перенаправляем ошибки также в первый поток.

crontab -r  - удаляем задачу, чтобы больше не крутились backup.


============================

распечатать столбец: | awk '{print $1}'

#!/bin/bash

echo "Programm is deleting empty lines and replaces small symbols with big one >

read -p "Please, enter file name: " FILE_NAME

cat $FILE_NAME | tr -s "\n" | tr [:lower:] [:upper:] > TEMPFILE

mv TEMPFILE $FILE_NAME

#!/bin/bash

echo "Program is monitoring the log /var/log/auth.log and informs about auth fa>

tail -n 5 -f /var/log/auth.log | grep -P ".+authentication failure.+"


#!/bin/bash

for y in {2010..2017}
 do
   for m in {01..12}
      do
        mkdir -p ./$y/$m
          for f in {001..005}
             do
               printf "00$f" 1 > ./$y/$m/$f.txt
             done
       done
 done

================================

поиск файлов:

find / -name 'ownersort.sh' 2>&1 | grep -v "Permission denied"

================================

Вот это последний аргумент получает:
Код: [Выделить]
echo ${@: -1}


==================================


NEW_NAME=$(printf "${PREFIX}%03d.jpg" "$COUNT")

подставили 3 динамических нуля перед переменной $COUNT

=================================================================

ДЗ первая задачка.

Можно сделать через set:

sed '/^$/d' (d - delete, /^$/ - пустая строка) ./test.txt | tr [a-z] [A-Z]
=================================================

Веб сервисы.

nGNIX - балансирует нагрузку, все запросы приходят на него.

сделаем несколько портов: 
8080    81     83, на них будет перенаправляться трафик.

Можно также сделать резервный сервер, можно делать трафик по весам.

Схема работы Apache2:

приходит пользователь, создается доп процесс и так для каждого пользователя.
(возможно, что модули уже заготовлены заранее).

процессы независимы, это безопасно.

минус: большое количество памяти нужно для открытия всех процессов.

htaccess файлы создаются в каждой папке отедьно, можно изменять права 


NGNIX всегда открывает один экземпляр и все пользователи идут на 1 
соединение.

+ производительность, не нужно большого объема памяти.
- не надежность.

htaccess файлы централизованы, можно изменять права только из одного места.

Также есть:
GWS - google web server
IIS от Microsoft

LAMP - LINUX Apache My SQL PHP
LNMP - Linux mySQL PHP

HTTP.

Создан в 1991 году создан CERN.
Передавался только текст, в 91 году создали http 1.0.
Добавили возможность передачи не текстовых данных.
в 99 году вышла HTTP 1.1, исп. до сих пор.
Сейчас вышел http 2.0.
(сущ. возможность установки долгого соединения между сервером и клиентом).
(Connection: Keep-alive)

Методы: GET - получить данные.
Есть также POST, примерно тоже самое.

Ответ - 200 OK.
201 - CREATED
204 - AUTHORISED

Сущ. также long pooling запросы - сервер ждем ответа и не закрывает соед,
но это черевато тем, что сервер может лечь.
Для того, чтобы это учесть, создали HTTP 2.0 - на уровне протокола 
есть долгое соединение поэтому меньше ресурсов.

Схема:

Apache - PHP-FPM - Сервер базы данных.

MPM мультипроцессорные модули:

mpm-prefork
+ хорошая безопасность - процесс изолирован от других.
- много памяти расходуется
все пользователи запускаются на уровне операционки от 
пользователя www-data

-itk
тоже что и prefork, но каждый пользователь может запускаться от
отдельного пользователя u1, u2, ...


-worker 
многопоточная система обработки запросов.
несколько потоков внутри одного процесса, куда приходят много пользователей.
если нагрузка большая, создается доп. процесс.

+ меньше памяти нужно, быстрее работает
- надежность ниже.

-event
ставится в apache2

поддерживает выделенный потом для каждого соединения и имеет дочерние 
потоки.
Похоже на worker.
Отличие - хорошо работает с keep alive, может быстро закрывать соединения.

Стандартно - ставим event или prefwork, думаем если большая нагрузка.

Есть ли apache:

sudo ss - tulpan - нет слова apache, нет порта 80.

нет, ставим:

sudo apt-cache search apache2
смотрим какие пакеты есть.

apache2 - нам нужен он!

sudo apt-get install apache2

ss - tulpan 
добавился порт 80.

apachectl -t -D DUMP_MODULES | grep mpm
(-t - проверить синтакс
-D - все файлы конфига)

Видим что у нас event.

чтобы посмотреть что 80 - это apache - запускаем команду от sudo.

файл конфига:

ls -l /etc/apache2/

apache2.conf - основаня конфиг.

Чтобы включить модуль, делаем на него символ ссылку и помещаем ее в 
mods-enabled.

аналогично sites-enabled.

смотрим apache2.conf:

cat apache2.conf | grep -v "^#.+" | grep -v "^$" | grep -v "^#"

KeepAlive On - если Off - всегда закрывается длинное соед.

LogLevel - на каком уровне пишутся логи.

User 
Group - от каких групп запускаются процессы.

Include ports.conf - подключатся порты.

AllowOverride None - если хотим с htaccess - ALL

Формат логов 
и в конце - хосты Includeoptional sites.

Тут ссылки на др. файлы, но Apache читает только этот.

Скопировали файл как резерв.

cd sites-available/

000-default  - то что работает, конфиг по умолчанию:

Host *:80 - наш порт

Почта вэб мастера, корневая директория DocumentRoot
где храняться логи - ниже (ErrorLog, CustomLog).

cd sites-enabled/

ls -l

это символическая ссылка на предыдущий файл.

cd /var/www/

Создаем папку где храняться файлы для нашего домена:
sudo mkdir 8080
cd 8080 

sudo nano index.html
(или sudo chown group:group . - поменяли владельца на нашего пользователя чтобы можно было записать)


Вводит HTML код:

<html>
<head>
<meta charset='utf-8'>
<title>Site 8080 </title></head>
<body>
<h1> Наш сайт доступен через порт 8080.</h1>

</body>

</html> 

cd etc/apache2/

создаем вирт хост.

cd sites-available/

grep -v "#" ./000-default.conf
смотрим конфиг.

sudo grep -v "#" ./000-default.conf > etc/apache2/sites-available/8080.conf

nano 8080.conf

Document root /var/www/8080

порт 8080 (*:8080>)

порт 8080 мы берем новый, т.к. в будущем на порту 80 будет висеть NGNIX - балансировщик.

перезапускаем апач:
systemctl reload apache2.service

netstat -tulpan | grep 8080 - ничего нет.
а 80 есть.

/etc/apache2/sites-enabled - нет симлинка, делаем его:

ln -s /etc/apache2/sites-available/8080.conf /etc/apache2/sites-enabled/8080.conf

systemctl reload apache2.service

снова нет порта 8080!

По умолчанию слушается только порт 80, нужно поправить в файле ports:

grep -r "80" /etc/apache2/

нам нужен файл ports.conf

Listen 80
Listen 8080

systemctl reload apache2.service

netstat -tulpan | grep 8080 - теперь порт есть!

Открываем сайт locahost:8080 в браузере - открылся.

создаем еще 2 таких сайта:

sudo grep -v "#" ./000-default.conf > /etc/apache2/sites-available/8081.conf
sudo grep -v "#" ./000-default.conf > /etc/apache2/sites-available/8082.conf

cd /sites-available/

меняем 8081 и 8082.conf

Создаем символьные ссылки.

редактируем ports.conf

создаем каталоги:

cd /var/www/
cp -r 8080 8081
cp -r 8080 8082

меняем права на папки.

меняем nano index.html

systemctl reload apache2.service

все ок!

netstat -tulpan | grep 80 - есть порты.

На сайт тоже можно зайти.


NGNIX:

apt update обновление списка пакетов.
apt-get install nginx

systemctl start nginx.service - не стартанул, т.к. порт 80 занят.

в  нам нужен файл ports.conf комментируем порт 80, т.к. теперь
он будет nginx.

systemctl start nginx.service
netstat -tulpan | grep 80 - есть порты.
так теперь и есть.


/var/www/
cd html

nano index.php

<?php
phpinfo();
?>

/locahost/index.php - в браузере - не заработало.

проверяем установлен ли php fpm:

смотрим файл:

ls -l /etc/php

вообще нет такой директории, значит нужно установить php fpm

apt-get install php-fpm

cd etc/php/
cd 7.3
cd fpm
ls -l

переходим в nginx настраиваем его для работы с php fpm:

cd /etc/nginx/

ls -l 

главный файл: 

ngnix.conf
открываем его:
nano
ищем секцию php:

тут нет

cd sites-available/

nano default

дописали index.php - приоритетный сайт:

pass PHP scripts = раскоментируем:

location
	inclide                    включить доп параметры для работы.
	
	fstcgi   ... версия 7.3    все направляем на сокет php.
	....
	}
	
ngnix -t

systemctl start nginx.service

связали NGNIX и PHP-FPM!

Делаем балансировку:
cd /etc/nginx/
cd conf.d/

эта директория сканируется автоматом:

создаем файл:

nano upstream.conf  название не важно, т.к. из директории читаются все файлы.
(см. файл nginx.conf - строка include /etc/nginx/conf.d/*.conf)

upstream http (любое имя) {

	server localhost:8080;
	server localhost:8081;
	server localhost:8082;

}

cd sites-available/   (в директории nginx!)

nano default

ищем: location/ {
proxy_pass http://http;   дописали, второе http, тк название балансировщика у нас тоже http.
это правило http, которое применяется к http трафику - первая часть выражения.

nginx -t
systemctl start nginx.service

в браузере открывается случайным образом 8080, 8081, 8082.

т.е. сейчас балансировка round-robin.

т.е. NGINX случайно разбрасывает запросы на Apache2 - 3 шт.

меняем на другое распределение:

открываем upstream.conf

upstream http (любое имя) {
least_conn;
	server localhost:8080;
	server localhost:8081;
	server localhost:8082;

}

Это балансировка с автоматическим определенмем наименее загр. узла.

Если хотим чтобы для одного пользователя был всегда один сервер:

upstream http (любое имя) {
ip_hash;
	server localhost:8080;
	server localhost:8081;
	server localhost:8082;

}

ngnix -t
systemctl start ngnix.service

Применилось, теперь в браузере всегда открыв 1 сайт, т.к. он закешировался по нашему IP.

Еще вариант:

upstream http (любое имя) {
hash $scheme$request_uri;    - на основании чего происходит запоминание и направление к определенному серверу. 

	server localhost:8080;
	server localhost:8081;
	server localhost:8082;

}

Можно ставить вес серверов.

upstream http (любое имя) {
least_conn;    - реальная балансировка по нагрузке, NGINX проверяет нагрузку сам.

	server localhost:8080 weight=10;
	server localhost:8081 weight=9;
	server localhost:8082 backup;

}


Также смотрим IPTable - брендмауэр по методичке.

Делаем 1 и 2 задания.
Сдавать - скришоты рабочих сайтов.


=====================================================================

Введение в GIT.

Как найти куда ведет переменная: APACHE_LOG_DIR?

grep -r "APACHE_LOG_DIR" /etc/apache2/

она есть в файле: 
etc/apache2/envars - там есть export, в файле указано, что это /etc/apache2$SUFFIX, а он указан выше, в настоящее время это ничего.

HTTP авторизация, есть файл, где храняться хэш и имена пользователей.

После того как создали файл, настраиваем apache чтобы он запрашивал пароль, если юзер не авторизован.

cd ~
htpasswd -c (новый файл, если дописываем - не нужно! иначе перезатрется) /etc/apache2/.htpasswd (. - скрытый файл) test (пользователь)
Вводим пароль - все ок.

nano .htpasswd
видим пользователя и хэш пароля.

cd /var/www/8080/

создаем файл:

nano .htaccess

В файле:
AuthTypee Basic базовая авторизация
AuthName "Please, enter your login and password" - сообщение для юзера
AuthUserFile /etc/apache2/.htpasswd - файл с паролем.
Require valid-user - пускаем только авторизованных пользователей.

Вышли.

По умолчанию access файл запрещен, меняем:

cd /etc/apache2/

nano apache.conf:

Ищем <Directory />

AllowOverride None -> All в двух местах - /var/www/ (частное правило) и просто Directory (общее правило). 

Второй вариант авторизации (через директорию, так быстрее работает):

Комментируем все в файле htaccess.

cd /etc/apache2/sites-available/

nano 8080.conf

дописываем:

<Directory "/var/www/8080">
AuthType Basic
AuthName "Please, enter your login and password"
AuthUserFile /etc/apache2/.htpasswd
Require valid-user
</Directory>

перепускаем апач.

проверяем синтаксис:

apache2ctl configtest

IPtables - задает правила для сетевого фильтра, работает в пространстве ядра Linux.

iptables -L - смотрим правила какие есть.

смотрим есть ли ssh сервер:

netstat -tulpan | grep 22

есть.

делаем политику по умолч drop для входн трафика:

iptables -P INPUT DROP

iptables -L

изменилось.

Пробуем подключиться по ssh locahost - timeout.
Даже изнутри не можем соединиться с собой же.

Разрешим порт 22, а потом запретим все.

Правило работает сверху вниз - одно правило выполнено, если есть другие на ту же тему, они уже не сканируются.

iptables -A INPUT -p tcp (если не указано, то для tcp+udp) -j DROP
iptables -A INPUT -p tcp  --dport=22 -j ACCEPT

не работает ssh locahost, т.к. все запрещено, разрешенное не читается после него.

удалим первое правило:
iptables -D (delete) INPUT -p tcp -j DROP

но это не удобно - в ручную удалять много правил.

сначала вставляем запрет:
iptables -A INPUT -p tcp -j DROP

потом перед ним ставим другое с разрешением:

iptables -L --line-numbers

смотрим нумерацию строк с 1..

iptables -I (вставляем) INPUT 1 (первая строка) -p tcp  --dport=22 -j ACCEPT

должно работать теперь, т.к. правило на разрешение стоит до запрета.

Снова вспоминаем iptables.

sudo iptables -L

iptables -P INPUT DROP

теперь с внешней машины нельзя попасть по ssh на виртуалку.

iptables -P INPUT ACCEPT - вернули обратно.

разрешаем только 22 порт:

iptables -A INPUT -p tcp  --dport=22 -j ACCEPT
iptables -P INPUT DROP

залогинится с другой машины по ssh можно, т.к. это как раз 22 порт.

iptables -I INPUT 1 -p tcp  --dport=8080 -j ACCEPT

+ в VBox пробрасывем порт 127.0.0.1 2280 -> 10.0.2.15 порт 8080

вставили новое правило в начало списка, теперь открывается наш сайт по порту 8080 на основной машине (не виртуальной).

iptables -F - сбрасываем таблицу по умолчанию.

Перенаправляем трафик:

iptables -t nat -A PREROUTING (на котором работает rediret) -p tcp --dport 8080 -j REDIRECT --to-port 8082

sudo iptables -L -t nat - смотрим наш редирект, нашу таблицу.

Теперь внутри виртуалки трафик заворачивает на 8082, хотя мы шли на 8080.

Оставим открытыми только 2 порта: 

if config - сотрим интерфейсы. enp0s3 - интернет lo - loopback.

iptables -A INPUT -i enp0s3 -p -tcp --dport 8080 -j ACCEPT
iptables -A INPUT -i enp0s3 -p -tcp --dport 8082 -j ACCEPT
iptables -P INPUT -i enp0s3 -p -tcp -j DROP
sudo iptables -L INPUT

Теперь 8082 и 8080 работают с внешней машины, остальные порты закрыты.

iptables -F

Новая задача:

iptables -A INPUT -p -tcp -i enp0s3 --dport 22 -j ACCEPT

все остальное запрещаем:

iptables -A INPUT -j DROP

Запретили соединяться изо все сетей кроме той, с которой разрешили, той, которая на интерфейсе: enp0s3.

GIT.

Это распределенная система контроля версий.
Она не просто централизована как предыдущая версия SVN, но она
еще и наспределена, любой клиент хранит всю информацию.

То есть если сервер отваливается, то какой-то из клиентов становится
сервером и все обращаются уже к нему.

ставим git:

sudo apt install git

git --version

создаем пустую директорию под проект:

mkdir git
cd git

git init инициализация папку под проект, появился скрытый каталог .git так хранится вся информация по проекту.

создаем несколько файлов в корне:

nano index.html

<html>
<head>
<meta charset='utf-8'>
<title>GIT lesson</title>
</head>
<body>
<h1>Git. First file.</h1>

</body>

</html> 

сохранили, вышли.

git status - файл не добавлен в индекс.

got add index.html - добавим в отслеживаемые.

git status  - зеденый.

делаем commit:

git commit -m "Create file index"

не работает, т.к. мы не представились:

git config user.email "test@i-filimonov.com" (указываем e-mail, который есть на github, вообще можно любой - пройдет, но будет ругаться.)
git config user.name "Test"

git commit -m "Create file index"

git status - в ветке master нечего комитить.

Далее создаем репозиторий на GitHub.

добавляем его на виртуалке:

git remote add origin https://... скопированный с хаба.

git branch -a есть только ветка master, зальем ее:

git push -u (первый раз создаем ветку, котом без нее) origin master

мануал:

git push --help - смотрим 

git status - все ок, нет изм.

Теперь добавим меню на сайт:

nano index.html

<html>
<head>
<meta charset='utf-8'>
<title>GIT lesson</title>
</head>
<body>
<h1>Git. First file.</h1>
<nav>
<ul>
<a href='#1'>One</a>
</ul>
</nav>
</body>
</html> 

git add .

git status

git commit -m "Add menu"

git status

git push
 ввели данные.

Смотрим на сайте: зеленым - то, что добавилось. Можно оставлять комментарии к коду.
Можно смотреть историю файла как он менялся.

Ветка - это цепочка коммитов.

можно ее отпачковать, а потом сделать merdge.

Создаем ветку:

git branch footer

Перекл на нее:

git checkout footer

git branch - смотрим ветки. Звездочка - где находимся.

git checkout master

git checkout -b footer2 - создать и сразу переключиться на новую ветку.

git checkout master

git branch --delete footer2 - удалили ветку. если в ней коммиты есть, то удаляем с -f, либо ее смёрджить.

git checkout footer

nano style.css

body {

}

nano index.html

<html>
<head>
<meta charset='utf-8'>
<title>GIT lesson</title>
</head>
<body>
<h1>Git. First file.</h1>
<nav>
<ul>
<a href='#1'>One</a>
</ul>
</nav>
<footer>
&copy 2020
</footer>
</body>
</html> 

git add .

git commit -m "Add footer"

git checkout master

cat index.html - в этой ветке нет последних изменений.

Слияние: перекл. на ту ветку, куда будем вливать.

git merge footer

cat index.html - теперь есть изменения.

удаляем ветку:

git branch --delete footer

Если есть конфликт:

git checkout -b menu-update

nano index.html

<html>
<head>
<meta charset='utf-8'>
<title>GIT lesson</title>
</head>
<body>
<h1>Git. First file.</h1>
<nav>
<ul>
<a href='#1'>One</a>
<a href="#2">Two</a>
</ul>
</nav>
<footer>
&copy 2020
</footer>
</body>
</html> 

git status
git add .
git commit -m "Menu update"

git checkout master
будем делать то, что противоречит предыдущему.

nano index.html

<html>
<head>
<meta charset='utf-8'>
<title>GIT lesson</title>
</head>
<body>
<h1>Git. First file.</h1>
<nav>
<ul>
<a href='#1'>One</a>
<a href="#3">Three</a>   на месте второго пункта добавляем третий пункт!
</ul>
</nav>
<footer>
&copy 2020
</footer>
</body>
</html> 

git status
git add .
git commit -m "Menu update in master branch"

git checkout menu-update

cat - тут пункт второй.

git checkout master

git merge menu-update 

ругается, разрешите конфилкты в ручную.

nano index.html

<html>
<head>
<meta charset='utf-8'>
<title>GIT lesson</title>
</head>
<body>
<h1>Git. First file.</h1>
<nav>
<ul>
<a href='#1'>One</a>
<a href="#3">Three</a>  
<a href="#2">Two</a>    оставили и то и другое, убрали маркеры.
</ul>
</nav>
<footer>
&copy 2020
</footer>
</body>
</html> 

git status

git add .
git commit -m "Merge conflic files"

ветки стились, merge произошел потому что мы ранее писали merge и
решили конфликт.

удаляем ветку:

git branch --delte menu-update

git log --all --graph

посмотрели в графике.

Популярные графические клиенты для GIT.

https://www.syntevo.com/smartgit/
https://git-fork.com/

Встроен редактор, но платный:

https://www.gitkraken.com/

Графический редактор под Win:

https://desktop.github.com/

Что такое pull request?

Механизм с помощью которого разработчики могут меняться кодом.

Новый разработчик хочет присоединиться, делает себе fork и clone 
на свой компьютер, работает и сливает его с основной версией с 
помощью pull request.

Создаем новый репозиторий на гитхабе:

Теперь нужно сделать fork данного репозитрия на сайте.
скопировали ссылку форка.

git clone адрес репозитория .  точка что в данную директорию.

поменяли файл в папке.

git add .
git status

git commit -m "Add new file"

представимся:

git config user.email
git config user.name

git push origin

https://github.com/Orazumov/group-linux-1.git


===========================================================

Docker.

SOA - сервисно ориентированная архитектура.

Архитектуры веб приложений:
-монолитная
запросы от пользователей  <---> NGINX -- Apache --- статические файлы				
												--- PHP (PH-FRM), Python, cgi --- скрипты, программы --- mySQL
минус: при обновлении приложений на сайте, может отклчится услуги, например телефония.
							
-SOA
Можно делать через докер, virtual машину.
но если мы выделили в VM по 2 ядра и 4GB оперативки, то другие процессы с ними работать уж не могут, 
т.е. ресурсы быстро расходятся для запуска VM. Т.е. максимум 6-7 VM можно запустить.

Если мы используем докер, он сразу не забирает память и ядра, т.е. максимум нужно следить за загрузкой.
Ресурсы выделяются не четко, а используются по мере необходимости.

Докер контейнеры даже если падают, нагрузка перераспределяется на оставшиеся, а упавшие можно перезапустить по crone.

С БД, которая в контейнере сложнее, т.к. при падении контейнера, БД может не восстановиться. Данные БД обычно выносят за пределы контейнера (забиндены), а служба БД висит в контейнере.

На 1 контейнер должна быть 1 служба. Т.е. на всех fronted контейнерах NGINX, на всех БД MySQL.
backend - php-fpm
DNS сервер тоже одинаковый на всех.

Плюс: все службы отдельно и все сразу упасть не может, т.к. есть физическое разнесение по серверам.
систему легко дорабатывать и поддерживать.

Нужно опробрасывать порты с реальной машины в docker, чтобы был к нему доступ. 
Порты пробрасываются черезз iptables.

Практика: 

docker.com 

https://docs.docker.com/install/linux/docker-ce/ubuntu/

действуем по инструкции на сайте:

Set up the repository: 1,2,3,4: x86 64 / amd 64.

Install docker engine-community (1,2,3).

Для работы с docker, нужно постоянно писать sudo, поэтому рекомендуется добавить
нашего пользователя в группу docker:

sudo usermod -aG docker your-user

после этого перегружаем VM.

Ищем образ, который будем разворачивать, образы находятся
в docker hub. https://hub.docker.com/

NGiNX: (https://hub.docker.com/_/nginx)

смотрим how to use this image.

команда в консоли:

sudo docker search nginx
нашли nginx.

sudo docker pull nginx
скачиваем образ.

sudo docker image list

есть 1 образ nginx, tag: latest, размер..

sudo docker run -d -p 81 (свободный на нашей машине):80 (порт внутри всегда 80) nginx

запустился контейнер, проверяем: 

sudo docker ps

ports: 0.0.0.0 (все адреса)

в браузере смотрим: localhost:81 - Welcome to Nginx!

Docker - это проигрыватель, в него загружаем image, и на основании него создается контейнер.

Докер - программа, которая умеет работать с контейнерами, имулирует вгнутреннюю файловую систему и сам берет себе ресурсы
динамически. 
На win и macos докер ставит vm light, а уже внутри нее ставит контейнер.
Поэтому лучше всего докер себе ведет на linux.

docker ps
видим что контейнер не запущен.

docker ps --all

показывает все контейнеры, когда создан и когда выход из него.

docker start ID скопировали из --all

запустили докер.

locahost:81 - Welcome to NGINX! в браузере.

cd /var/www/8080
ls

index.html

прикрепим папку к контейнеру.

docker run -d -p 82 (внешний порт поменяли):80(внутр порт всегда 80!) -v /var/www/8080:/usr/share/nginx/html (взяли и документации) nginx

locahost:82 загрузился наш сайт в браузере!

docker ps

видим 2 контейнера.

пусть нам нужен ID контейнеров:

docker ps | grep -v CONTAINER | awk '{print $1}'

хотим все разово остановить:

for i in `docker ps | grep -v CONTAINER | awk '{print $1}'`; do echo $i; done;
посмотрели

for i in `docker ps | grep -v CONTAINER | awk '{print $1}'`; do docker stop $i; done;
остановили все 3

for i in `docker ps -all | grep -v CONTAINER | awk '{print $1}'`; do docker start $i; done;
подняли все 3 контейнера

поставим mySQL:

docker search mySQL

нашли mysql 

скачиваем образ:

docker pull mysql

при запуске сразу нужно задавать пароль, иначе контейнер сразу упадет 
при этом docker не пишет нормальной причины падения, поэтому важно изучать документацию того, что мы запускаем.

docker image list

docker run --name mysql-not-work -d mysql
(делаем неправильно, специально).

docker ps - нового контейнера тут нет.

docker ps --all 

mysql лежит, но причина не ясна.

теперь далеаем правильно:

docker run --name mysql1 -e MYSQL_ROOT_PASSWORD=1234 -d mysql

docker ps 

есть!

заходим вовнутрь:

docker exec --help

docker exec -ti mysql1 bash  внутри контейнера запустить bin bash

зашли!! 

whoami

ls

cat passwd - свои пользователи, нет тех, которые на машине.

mysql -u root -pack

вошли внутрь mysql!

use mysql;

SELECT User, Host from mysql.user;

Внутри контейнера только консоль, графического интерфейса не поставить.

Удаляем контейнер через force, т.к. он работает сейчас:

for i in `docker ps -all | grep -v CONTAINER | awk '{print $1}'`; do docker rm -f $i; done;

Сделаем отдельный контейнер и поставим в него PHP My Admin.

Делаем через графику:

Kitematic.com

https://kitematic.com/

https://github.com/docker/kitematic

Качаем под Ubuntu.

Открываем программу.

lpadmin 
11
....!!

ставим mysql
переходим в настройки, задаем root password.

Hostname/ports смотрим какие внешние и внутренние порты.

ставим phpmyadmin

настройки: /usr/bin/gnome-terminal - ставим.

Жмем mysql EXEC.

вошли!

набираем:

mysql -u root ..
!!!

в браузере открываем localhost:32772  (порт посмотрели в настройках).
рутом войти нельзя.

контейнеры друг друга не видят:

PHP myadmin : Network:

Link: mysql   ALIAS db

теперь снова заходим:

localhost:32773 (порт уже поменялся, проверили!)

root + pass

зашли!

PHP-FPM - Fast CGI (расшифровка).

https://hub.docker.com/_/wordpress how to use this image - описание как поставить внутрь 












=============================

Что сейчас установлено:

# sudo dpkg --get-selections
























